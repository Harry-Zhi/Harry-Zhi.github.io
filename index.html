<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <title>Shuaifeng Zhi</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-136083545-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-136083545-1');
  </script>

</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Shuaifeng Zhi</name>
              </p>
              <p>I am now a Lecturer (Assistant Professor) at the Department of Electronic Science and Technology, National University of Defense Technology (NUDT), China. 
              <br>
                Prior to being an academic scholar, I obtained my Ph.D degree at <a href="http://www.imperial.ac.uk/dyson-robotics-lab/" target="_blank">The Dyson Robotics Lab at Imperial College</a>, 
                supervised by <a href="https://www.doc.ic.ac.uk/~ajd/" target="_blank">Prof. Andrew J. Davison</a> and <a href="https://wp.doc.ic.ac.uk/sleutene/" target="_blank">Dr. Stefan Leutenegger</a>;
                finished my MSc.Eng and B.Eng in NUDT, China.
                <br>
                <br>
                My research interest lies in semantic SLAM and semantic neural representations, combining semantics and SLAM systems using learning-based approaches. 
              </p>
              <p align=center>
                <a href="mailto:s.zhi17@imperial.ac.uk">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.co.uk/citations?user=5ls6RgQAAAAJ&hl=en" target="_blank">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/shuaifeng-zhi-3b4418103/" target="_blank"> LinkedIn </a> &nbsp/&nbsp
                <a href="https://twitter.com/Shuaifeng_Zhi" target="_blank"> Twitter </a>
              </p>
            </td>
            <td width="33%">
              <img src="images/Shuaifeng_circle.png">
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Event and News</heading>
              <p>
                Jan 2022: Happy to announce that our paper <a href="https://shikun.io/projects/regional-contrast/" target="_blank">ReCo</a> got accepted to ICLR 2022.
              </p>
              
              <p>
                Oct 2021: Attended ICCV 2021 <a href="http://ivl.cs.brown.edu/3DReps/" target="_blank">3DReps Workshop</a> and presented Semantic-NeRF in poster session.
              </p>
              <p>
                July 2021: Happy to announce that our paper <a href="https://shuaifengzhi.com/Semantic-NeRF/" target="_blank">Semantic-NeRF</a> got accepted to ICCV 2021 as <font color="Tomato"><strong>Oral Presentation (top 3%)</strong></font>!
              </p>
              <p>
                Feb 2019: One paper got accepted to CVPR 2019.
              </p>
              <p>
                July 2018: Participated International Computer Vision Summer School (<a href="http://iplab.dmi.unict.it/icvss2018/Home" target="_blank">ICVSS 2018</a>) in Sicily, Italy.
              </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="100%" valign="middle">
                <heading>Publications</heading>
              </td>
            </tr>
        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="25%"><img src="images/reco_intro_long.png" alt="PontTuset" width="160" style="border-style: none">
              <td width="75%" valign="top">
                <p>
                    <papertitle>Bootstrapping Semantic Segmentation with Regional Contrast</papertitle>
                  </a>
                  <br>
                 <a href="https://shikun.io/" target="_blank"> Shikun Liu</a>, <strong>Shuaifeng Zhi</strong>,<a href="https://www.robot-learning.uk/Edward Johns" target="_blank"> Edward Johns</a>,  <a href="https://www.doc.ic.ac.uk/~ajd/" target="_blank">Andrew J. Davison</a>
                  <br>
                  <em>International Conference on Learning Representations (ICLR)</em>, 2022
                  <br>
                  <a href="https://arxiv.org/abs/2104.04465" target="_blank">arxiv</a> /
                  <a href="https://github.com/lorenmt/reco" target="_blank">code</a> /
                  <a href="https://shikun.io/projects/regional-contrast" target="_blank">project page</a>

                </p>
                <p>
                  We present ReCo, a new contrastive learning framework designed at a regional level to assist learning in semantic segmentation. 
                  ReCo performs (semi-)supervised pixel-level contrastive learning on a sparse set of hard negative pixels. 
                  With minimal extra memory footprint,
                  Reco boosts exsiting baselines by a large margin, revealing hierarchical similarities of various semantic classes as well.
                </p>
              </td>
          </tr>

<!-- 
          <tr onmouseout="iLabel_still()" onmouseover="iLabel_still_mouse_on()">
            <td width="25%">
              <div id='iLabel_on' class='hidden'><img src="images/iLabel_still_mouse_on.jpg"  alt="PontTuset" width="188" style="border-style: none"></div>
              <div id='iLabel_off'>
                  <img src="images/iLabel_still.png"  alt="PontTuset" width="160" style="border-style: none">

              </div>
              <script type="text/javascript">
                function iLabel_still_mouse_on() {
                  document.getElementById('iLabel_on').style.display = 'inline';
                  document.getElementById('iLabel_off').style.display = 'none';
                }
                function iLabel_still() {
                  document.getElementById('iLabel_on').style.display = 'none';
                  document.getElementById('iLabel_off').style.display = 'inline';
                }
                iLabel_still()
              </script>
            </td>
            <td width="75%" valign="middle">
              <p>
                  <papertitle>iLabel: Interactive Neural Scene Labelling</papertitle>
                </a>
                <br>
                <strong>Shuaifeng Zhi<sup>*</sup></strong>, <a href="https://edgarsucar.github.io/" target="_blank">Edgar Sucar<sup>*</sup></a>,  Andre Mouton, Iain Haughton, 
                <a href="https://wp.doc.ic.ac.uk/twl15/" target="_blank">Tristan Laidlow</a>, <a href="https://www.doc.ic.ac.uk/~ajd/" target="_blank">Andrew J. Davison</a> 
                <br>
                <em>arxiv pre-print</em>
                <br>
                <a href="https://arxiv.org/abs/2111.14637" target="_blank">arxiv</a> /
                <a href="https://youtu.be/bL7RZaMhRbk" target="_blank">video</a> /
                <a href="https://edgarsucar.github.io/ilabel/" target="_blank">project page</a>
              </p>
              <p>
                We build an online interactive 3D scene labelling and understanding system upon 3D neural field representation of geometry, colour and semantics.
                <br>
              </p>
            </td>
          </tr> -->


          <tr onmouseout="semantic_nerf_stop()" onmouseover="semantic_nerf_start()">
            <td width="25%">
              <div id='semantic_nerf_opt' class='hidden'><img src="images/Semantic-NeRF_teaser.gif"  alt="PontTuset" width="188" style="border-style: none"></div>
              <div id='semantic_nerf_still'>
                  <img src="images/Semantic_NeRF_still.png"  alt="PontTuset" width="160" style="border-style: none">

              </div>
              <script type="text/javascript">
                function semantic_nerf_start() {
                  document.getElementById('semantic_nerf_opt').style.display = 'inline';
                  document.getElementById('semantic_nerf_still').style.display = 'none';
                }
                function semantic_nerf_stop() {
                  document.getElementById('semantic_nerf_opt').style.display = 'none';
                  document.getElementById('semantic_nerf_still').style.display = 'inline';
                }
                semantic_nerf_stop()
              </script>
            </td>
            <td width="75%" valign="middle">
              <p>
                <!-- <a href="https://drive.google.com/file/d/1shvItvx_8Sb8QNXhrOXkuRmx2618iwNJ/view?usp=sharing"> -->
                  <papertitle>In-Place Scene Labelling and Understanding with Implicit Scene Representation</papertitle>
                </a>
                <br>
                <strong>Shuaifeng Zhi</strong>, <a href="https://wp.doc.ic.ac.uk/twl15/" target="_blank">Tristan Laidlow</a>, <a href="https://wp.doc.ic.ac.uk/sleutene/" target="_blank">Stefan Leutenegger</a>, <a href="https://www.doc.ic.ac.uk/~ajd/" target="_blank">Andrew J. Davison</a>
                <br>
                <em>International Conference on Computer Vision (ICCV)</em>, 2021
                <br>
                <font color="red"><strong>(Oral Presentation)</strong></font>
                <br>
                <a href="https://arxiv.org/abs/2103.15875" target="_blank">arxiv</a> /
                <a href="https://youtu.be/FpShWO7LVbM" target="_blank">video</a> /
                <a href="https://www.bilibili.com/video/BV1FK4y1M7PC" target="_blank">video (bilibili)</a> /
                <a href="https://shuaifengzhi.com/Semantic-NeRF/" target="_blank">project page</a>
              </p>
              <p>
                We show that neural radiance fileds (NeRF) contains strong priors for scene cluster and segmentation. The internal multi-view consistency and smoothness make the training process itself a multi-view semantic fusion process.
                Such a scene-specific implcit semantic representation can be efficiently learned with various sparse or noisy annotations, leading to accurate dense labelling of the full scene.
                <br>
              </p>
            </td>
          </tr>

          <tr onmouseout="scenecode_stop()" onmouseover="scenecode_start()">
              <td width="25%">
                <div id='scenecode_opt' class='hidden'><img src="images/SceneCode_small_size.gif"></div>
                <div id='scenecode_still'>
                    <!-- <a href="images/SceneCode_small_size.gif"></a><img src="images/SceneCode_still.png"></a> -->
                    <img src="images/SceneCode_still.png">

                </div>
                <script type="text/javascript">
                  function scenecode_start() {
                    document.getElementById('scenecode_opt').style.display = 'inline';
                    document.getElementById('scenecode_still').style.display = 'none';
                  }
                  function scenecode_stop() {
                    document.getElementById('scenecode_opt').style.display = 'none';
                    document.getElementById('scenecode_still').style.display = 'inline';
                  }
                  scenecode_stop()
                </script>
              </td>
              <td width="75%" valign="middle">
                <p>
                  <!-- <a href="https://drive.google.com/file/d/1shvItvx_8Sb8QNXhrOXkuRmx2618iwNJ/view?usp=sharing"> -->
                    <papertitle>SceneCode: Monocular Dense Semantic Reconstruction using Learned Encoded Scene Representations</papertitle>
                  </a>
                  <br>
                  <strong>Shuaifeng Zhi</strong>, Michael Bloesch, <a href="https://wp.doc.ic.ac.uk/sleutene/" target="_blank">Stefan Leutenegger</a>, <a href="https://www.doc.ic.ac.uk/~ajd/" target="_blank">Andrew J. Davison</a>
                  <br>
                  <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2019
                  <br>
                  <a href="https://arxiv.org/abs/1903.06482" target="_blank">arxiv</a> /
                  <a href="https://www.youtube.com/watch?v=MCgbgW3WA1M" target="_blank">video</a>
                </p>
                <p>
                  We show that an efficient code representation is able to control the semantic label prediction of an image. 
                  Latent codes of overlapping images can be jointly optimised to perform coherent semantic fusion.
                  We also show how this approach can be used within a monocular keyframe based semantic 
                  mapping system where a similar code approach is used for geometry.
                  <br>
                </p>
              </td>
            </tr>




          <tr>
              <td width="25%"><img src="images/C&G2017.png" alt="PontTuset" width="160" style="border-style: none">
                <td width="75%" valign="top">
                  <p>
                      <papertitle>Toward real-time 3D object recognition: A lightweight volumetric CNN framework using multitask learning</papertitle>
                    </a>
                    <br>
                    <strong>Shuaifeng Zhi</strong>, Yongxiang Liu,  Xiang Li, <a href="http://yulanguo.me/" target="_blank">Yulan Guo</a>
                    <br>
                    <em>Computers & Graphics</em>, 2017
                    <br>
                    <a href="data/ZhiCG2018.bib">bibtex</a>
                  </p>
                  <p>
                    We propose LightNet, a light-weight 3D volumetric CNN for real-time 3D object classification.
                  </p>
                  <p>
                    This paper subsumes the 3DOR 2017 paper <em>LightNet</em>.
                  </p>
                </td>
            </tr>

        
          <tr>
              <td width="25%"><img src="images/3DOR_2017_small.png" alt="PontTuset" width="160" style="border-style: none">
                <td width="75%" valign="top">
                  <p>
                      <papertitle>LightNet: A Lightweight 3D Convolutional Neural Network for Real-Time 3D Object Recognition</papertitle>
                    </a>
                    <br>
                    <strong>Shuaifeng Zhi</strong>, Yongxiang Liu,  Xiang Li, <a href="http://yulanguo.me/" target="_blank">Yulan Guo</a>
                    <br>
                    <em>Eurographics Workshop on 3D Object Retrieval (3DOR)</em>, 2017
                    <br>
                    <a href="data/Zhi3DOR2017.bib">bibtex</a>
                  </p>
                </td>
            </tr>


        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Service</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="25%"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <p>
                Reviewer in 2022, CVPR, ICLR, ICML, ICME
                <br>
                <br>
                Reviewer in 2021, CVPR, ICCV, NeurIPS, ICLR, ICME, IJCNN
                <br>
                <br>
                Reviewer in 2020, ICME
                <br>
                <br>
                Reviewer in 2019, CVPR-W, ICCV-W, ICRA-W
                <br>
                <br>
              </p>
            </td>
          </tr>
          <tr>
            <td width="25%"><img src="images/imperial_logo.svg"></td>
            <td width="75%" valign="center">
              <p>
                <a href="https://www.doc.ic.ac.uk/~ajd/Robotics/">
                  Lab Assistant, Robotics (Online with Coppeliasim!), Spring 2021
                </a>
                <br>
                <br>
                <a href="https://www.doc.ic.ac.uk/~ajd/Robotics/index.html">
                  Lab Assistant, Robotics , Autumn 2019
                </a>
                <br>
                <br>
                <a href="https://wp.doc.ic.ac.uk/sleutene/teaching/co433-advanced-robotics/">
                  Lab Assistant, Robotics , Spring 2019
                </a>
                <br>
                <br>
                <a href="https://www.doc.ic.ac.uk/~ajd/Robotics/index.html">
                  Lab Assistant, Robotics , Autumn 2018
                </a>
                <br>
                <br>
                <a href="https://wp.doc.ic.ac.uk/sleutene/teaching/co433-advanced-robotics/">
                  Lab Assistant, Advanced-Robotics, Spring 2018
                </a>
                <br>
              </p>
            </td>
          </tr>
        </table>



        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                  Thank Dr. Jon Barron for sharing the <a href="https://github.com/jonbarron/jonbarron_website"> source code</a> of the website.
                  </font>
              </p>
            </td>
          </tr>
        </table>
        <script type="text/javascript">
          var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
        </script>
        <script type="text/javascript">
          try {
            var pageTracker = _gat._getTracker("UA-7580334-1");
            pageTracker._trackPageview();
          } catch (err) {}
        </script>
        </td>
    </tr>
  </table>
</body>

</html>
